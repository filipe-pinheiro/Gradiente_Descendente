{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588d6081-5d7c-46bb-bc97-2051ade9455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d82274-8706-4123-bb54-0689fd60645b",
   "metadata": {},
   "source": [
    "### Modelo de Regressão Linear Simples\n",
    "\n",
    "O modelo de regressão linear simples é dado por:\n",
    "\n",
    "$$\n",
    "\\hat{y}^{(i)} = h_\\theta(x^{(i)}) = \\theta_0 + \\theta_1 x^{(i)}\n",
    "$$\n",
    "\n",
    "Sendo $x^{(i)}$ o valor da característica do exemplo \\( i \\).\n",
    "\n",
    "---\n",
    "\n",
    "### Função de Custo\n",
    "\n",
    "A função de custo utilizada é:\n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} \\left( \\hat{y}^{(i)} - y^{(i)} \\right)^2\n",
    "$$\n",
    "\n",
    "Essa função é o **Erro Quadrático Médio (MSE)**. Ela serve para monitorar o erro da predição em relação aos valores reais das amostras, à medida que os parâmetros $\\theta_0$ e $\\theta_1$ são ajustados.\n",
    "\n",
    "Sua implementação, está descrita abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344f9a6f-badf-4310-b10a-b8974c59c6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Função de custo\n",
    "def calcular_custo(theta_values, features, targets, samples):\n",
    "    theta_0 = theta_values[0]\n",
    "    theta_1 = theta_values[1]\n",
    "    sigma = 0\n",
    "    \n",
    "    for i in range(samples):\n",
    "        pred = theta_0 + theta_1 * features[i]\n",
    "        erro = pred - targets[i]\n",
    "        sigma += erro**2\n",
    "\n",
    "    return (1/(2*samples)) * sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351051c8-6926-46ca-b3f6-b37fea238150",
   "metadata": {},
   "source": [
    "###  Cálculo do Gradiente\n",
    "\n",
    "O cálculo do gradiente se dá por meio da derivada parcial da função de custo.  \n",
    "Na implementação **batch**, todos os dados disponíveis são utilizados para calcular o gradiente, por meio da fórmula do somatório descrita abaixo:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^{m} \\left( \\hat{y}^{(i)} - y^{(i)} \\right) x_j^{(i)}\n",
    "$$\n",
    "\n",
    "A sua implementação, é dada pela função abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1952737c-5ac0-4802-a865-e3aa34ca41ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Calcular o gradiente\n",
    "def calcular_gradiente(theta_values, features, targets, samples):\n",
    "    theta_0 = theta_values[0]\n",
    "    theta_1 = theta_values[1]\n",
    "    sigma_0 = 0\n",
    "    sigma_1 = 0\n",
    "\n",
    "    for i in range(samples):\n",
    "        pred = theta_0 + theta_1 * features[i]\n",
    "        erro = pred - targets[i]\n",
    "        sigma_0 += erro\n",
    "        sigma_1 += erro * features[i]\n",
    "        \n",
    "    grad_theta_0 = (1/samples) * sigma_0\n",
    "    grad_theta_1 = (1/samples) * sigma_1\n",
    "\n",
    "    return [grad_theta_0, grad_theta_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf42c200-e1c5-47d5-9d23-6c456fabe7dd",
   "metadata": {},
   "source": [
    "### Atualização dos Parâmetros $\\theta$\n",
    "\n",
    "Para atualizar os parâmetros $\\theta$, é necessário subtrair o valor atual pelo gradiente multiplicado pela taxa de aprendizado $\\alpha$.  \n",
    "\n",
    "Essa fórmula é utilizada porque o gradiente aponta na direção de **maior aumento** da função de custo. Logo, para minimizar essa função, devemos nos mover na **direção oposta ao gradiente** — por isso o sinal negativo.\n",
    "\n",
    "O valor de $\\alpha$ determina o tamanho dos “passos” dados em direção ao mínimo da função de custo. Quando $\\alpha$ é muito grande, os passos podem ser largos demais e **ultrapassar o mínimo**, dificultando a convergência. Quando $\\alpha$ é muito pequeno, os passos são lentos e o treinamento pode demorar a convergir.\n",
    "\n",
    "A fórmula de atualização dos parâmetros é:\n",
    "\n",
    "$$\n",
    "\\theta_j := \\theta_j - \\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta_j}\n",
    "$$\n",
    "\n",
    "Sua implementação é mostrada abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bd9c50-e1b7-4023-9b98-29ecbad33b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Atualização do theta\n",
    "def atualizar_theta(theta_values, features, targets, samples, learning_rate, num_iters):\n",
    "    theta_0 = theta_values[0]\n",
    "    theta_1 = theta_values[1]\n",
    "    sigma_0 = 0\n",
    "    sigma_1 = 0\n",
    "    armazenar_custo = []\n",
    "    armazenar_theta_0 = []\n",
    "    armazenar_theta_1 = []\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        armazenar_custo.append(calcular_custo([theta_0, theta_1], features, targets, samples))\n",
    "        armazenar_theta_0.append(theta_0)\n",
    "        armazenar_theta_1.append(theta_1)\n",
    "        grad = calcular_gradiente([theta_0, theta_1], features, targets, samples)\n",
    "        theta_0 = theta_0 - learning_rate * grad[0]\n",
    "        theta_1 = theta_1 - learning_rate * grad[1]\n",
    "        \n",
    "\n",
    "    return [theta_0, theta_1], armazenar_custo, [armazenar_theta_0, armazenar_theta_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8325c68-be71-4800-8c50-adb0c4c6c6ba",
   "metadata": {},
   "source": [
    "---\n",
    "## Aplicação do gradiente batch\n",
    "\n",
    "No exemplo abaixo, é utilizado um conjunto de dados fictício, onde a primeira coluna descreve o tamanho das casas e a segunda, o valor delas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8322b7fb-caf4-4501-a1c4-632145c7c835",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Carregar e formatar dados\n",
    "data = np.loadtxt(\"./Data/data1.txt\", delimiter = \",\")\n",
    "x = data[:, 0]\n",
    "y = data[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3511985d-e1fe-4958-b75b-58debc9672df",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Disposição dos dados no plano\n",
    "plt.scatter(x, y, marker = \"+\")\n",
    "plt.title('Exemplo de gráfico com legenda')\n",
    "plt.xlabel('Área da casa (pés)')\n",
    "plt.ylabel('Valor da casa')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37593a6e-4d72-4b4a-a6a9-18275b16f27f",
   "metadata": {},
   "source": [
    "Aqui é realizada a inicialização dos parâmetros. Note que o vetor $\\theta$ é iniciado com $\\theta_0 = 0$ e $\\theta_1 = 0$,  pois ainda não conhecemos seus valores ideais. Por padrão, ambos começam com esse valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eb2a9a-5400-4baf-9664-e9912ae51c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Inicialização dos parâmetros\n",
    "theta = [0, 0]\n",
    "m = len(x)\n",
    "alpha = 0.01\n",
    "iteracoes = 1500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5215c4a6-789d-4f6d-a07c-87f6d476277a",
   "metadata": {},
   "source": [
    "Com a aplicação na função de atualização de theta implementada acima:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e7aeda-81d3-45c4-ba45-1071c7e21a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_atualizado, custo_atualizado, hist_theta = atualizar_theta(theta, x, y, m, alpha, iteracoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f0a8be-0a74-4729-8f90-32d62f8173f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##O valor atualizado de theta:\n",
    "theta_atualizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f43ad5e-c7f0-4300-a93b-40e53cc37e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Visualição do custo\n",
    "plt.plot(custo_atualizado)\n",
    "plt.title('Custo J(θ) x Iterações')\n",
    "plt.xlabel('Iterações')\n",
    "plt.ylabel('J(θ)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153afeba-993c-46d4-82c3-93c72b3a3cdc",
   "metadata": {},
   "source": [
    "Para validar o modelo, o código abaixo gera os valores de $\\theta$ com uma função já implementada pelo Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b7c6dd-6dd1-40d1-b62c-645b8b5753d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Comparando com os parâmetros de theta do scikit-Learn\n",
    "modelo = LinearRegression()\n",
    "modelo.fit(x.reshape(-1, 1), y)\n",
    "\n",
    "theta_scikit = [modelo.intercept_, modelo.coef_[0]]\n",
    "theta_scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cfa621-eb95-4ee4-b3fe-ee81f3c0f841",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Visualização da reta, com base nos valores de theta gerados\n",
    "y_previstos = theta_atualizado[0] + theta_atualizado[1] * x\n",
    "\n",
    "plt.scatter(x, y, marker = \"+\")\n",
    "plt.plot(x, y_previstos, color = \"red\")\n",
    "plt.title('Exemplo de gráfico com legenda')\n",
    "plt.xlabel('Área da casa (pés)')\n",
    "plt.ylabel('Valor da casa')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351591d1-0dea-4863-a8fe-b9093e80a0c3",
   "metadata": {},
   "source": [
    "### Análise do Custo em Relação aos Parâmetros\n",
    "\n",
    "Nesta etapa, analisamos como os valores de $\\theta$ evoluem ao longo das iterações, observando o comportamento do gradiente e sua trajetória até a convergência.\n",
    "\n",
    "Inicialmente, calcula-se o custo para cada combinação de $\\theta_0$ e $\\theta_1$, a fim de observar a forma da superfície da função de custo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bdd32a-3f77-4cf7-ad52-01ffbd827668",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Cálculo e formatação das variáveis para plot da superfície\n",
    "theta_0_values = np.linspace(-10, 10, 100)\n",
    "theta_1_values =  np.linspace(-10, 10, 100)\n",
    "T0, T1 = np.meshgrid(theta_0_values, theta_1_values)\n",
    "all_custo = []\n",
    "\n",
    "for i in range(100):\n",
    "    for j in range(100):\n",
    "        all_custo.append(calcular_custo([theta_0_values[i], theta_1_values[j]], x, y, int(len(x))))\n",
    "\n",
    "J_vals = np.array(all_custo).reshape(100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f99e24-b8a0-405a-ac87-dd4bf6db0f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(T0, T1, J_vals, cmap='viridis', edgecolor='none')\n",
    "ax.set_title('Superfície da Função de Custo')\n",
    "ax.set_xlabel(r'$\\theta_0$')\n",
    "ax.set_ylabel(r'$\\theta_1$')\n",
    "ax.set_zlabel(r'$J(\\theta)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b30b242-e2f8-4bd7-b743-079e4df37c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "cp = plt.contourf(T0, T1, J_vals, levels=50, cmap='viridis')\n",
    "plt.colorbar(cp)\n",
    "plt.title('Contorno da Função de Custo $J(\\\\theta)$')\n",
    "plt.xlabel(r'$\\theta_0$')\n",
    "plt.ylabel(r'$\\theta_1$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a7cd74-5482-4738-a10f-2daf31ba30c4",
   "metadata": {},
   "source": [
    "Agora analisando a trajetória do gradiente em cima da superfície do custo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd09cf-ea61-4246-bdc8-4e6710afd5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot(hist_theta[0], hist_theta[1], custo_atualizado, color='red', marker='o', markersize=3, linewidth=2, label='Trajetória')\n",
    "ax.plot_surface(T0, T1, J_vals, cmap='viridis', edgecolor='none')\n",
    "ax.set_title('Superfície da Função de Custo')\n",
    "ax.set_xlabel(r'$\\theta_0$')\n",
    "ax.set_ylabel(r'$\\theta_1$')\n",
    "ax.set_zlabel(r'$J(\\theta)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c02c1fd-a7ae-442e-94dc-9f0d0aaa07f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "cp = plt.contourf(T0, T1, J_vals, levels=50, cmap='viridis')\n",
    "plt.colorbar(cp)\n",
    "plt.plot(hist_theta[0], hist_theta[1], color='red', marker='o', markersize=3, linewidth=1.5, label='Trajetória do Gradiente')\n",
    "plt.title('Contorno da Função de Custo $J(\\\\theta)$')\n",
    "plt.xlabel(r'$\\theta_0$')\n",
    "plt.ylabel(r'$\\theta_1$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47789047-cc93-48f4-9164-294abeb4a5c7",
   "metadata": {},
   "source": [
    "---\n",
    "### Teste de Inicialização de Parâmetros\n",
    "\n",
    "Quando se utiliza o gradiente descendente, existe o risco de o algoritmo convergir para **mínimos locais** em vez do **mínimo global**. Uma estratégia para mitigar esse problema é **inicializar os parâmetros $\\theta$ em diferentes posições**, forçando o gradiente a explorar melhor o espaço de busca.\n",
    "\n",
    "Desta vez, realizaremos o mesmo procedimento, mas com $\\theta_0$ iniciado em **-10** e $\\theta_1$ em **10**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8443ae-af95-4865-971c-f93ccc0e2123",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Cálculo de novo gradiente com valores de theta atualizados.\n",
    "iteracoes = 3500\n",
    "theta_atualizado, custo_atualizado, hist_theta = atualizar_theta([-10, 10], x, y, m, alpha, iteracoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64cd5ba-5174-4fa1-94e0-4df3bea1e35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot(hist_theta[0], hist_theta[1], custo_atualizado, color='red', marker='o', markersize=3, linewidth=2, label='Trajetória')\n",
    "ax.plot_surface(T0, T1, J_vals, cmap='viridis', edgecolor='none')\n",
    "ax.set_title('Superfície da Função de Custo')\n",
    "ax.set_xlabel(r'$\\theta_0$')\n",
    "ax.set_ylabel(r'$\\theta_1$')\n",
    "ax.set_zlabel(r'$J(\\theta)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f682d0-0c58-401c-b2b7-149307f64b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "cp = plt.contourf(T0, T1, J_vals, levels=50, cmap='viridis')\n",
    "plt.colorbar(cp)\n",
    "plt.plot(hist_theta[0], hist_theta[1], color='red', marker='o', markersize=3, linewidth=1.5, label='Trajetória do Gradiente')\n",
    "plt.title('Contorno da Função de Custo $J(\\\\theta)$')\n",
    "plt.xlabel(r'$\\theta_0$')\n",
    "plt.ylabel(r'$\\theta_1$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4045b678-afe1-4223-bf98-9412a89ca8fe",
   "metadata": {},
   "source": [
    "Observa-se que os valores iniciais de $\\theta$ influenciaram diretamente a trajetória de otimização. Apesar do aumento no número de iterações, o gradiente produziu um novo conjunto de parâmetros $\\theta$, com uma trajetória mais longa — o que era esperado, dado que os valores iniciais estavam mais distantes do mínimo.\n",
    "\n",
    "Esse experimento reforça a importância da escolha da **inicialização dos parâmetros**, que pode impactar tanto a velocidade de convergência quanto a qualidade da solução encontrada.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
